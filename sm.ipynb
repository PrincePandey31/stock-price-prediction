{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a4d44",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------\n",
    "# Config\n",
    "# -------------------------------\n",
    "DATA_FILE = \"HistoricalQuotes.csv\"   # Your dataset CSV\n",
    "MODEL_PATH = \"xgb_apple.model\"\n",
    "SCALER_PATH = \"scaler.pkl\"\n",
    "FEATURES_PATH = \"features.pkl\"\n",
    "LOG_PATH = \"training_log.txt\"\n",
    "\n",
    "# -------------------------------\n",
    "# Load Data\n",
    "# -------------------------------\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    raise FileNotFoundError(f\"‚ùå CSV not found: {DATA_FILE}\")\n",
    "\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "\n",
    "# --- Flatten MultiIndex headers if present ---\n",
    "if isinstance(df.columns, pd.MultiIndex):\n",
    "    df.columns = [\n",
    "        \"_\".join([str(c) for c in col if c]).strip()\n",
    "        for col in df.columns\n",
    "    ]\n",
    "\n",
    "# --- Clean headers ---\n",
    "df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "\n",
    "# --- Rename common variations ---\n",
    "rename_map = {\n",
    "    \"date\": \"Date\",\n",
    "    \"timestamp\": \"Date\",\n",
    "    \"close/last\": \"Close\",\n",
    "    \"adj close\": \"Close\",\n",
    "    \"close\": \"Close\",\n",
    "    \"price\": \"Close\",\n",
    "    \"open\": \"Open\",\n",
    "    \"high\": \"High\",\n",
    "    \"low\": \"Low\",\n",
    "    \"volume\": \"Volume\",\n",
    "}\n",
    "df.rename(columns={c: rename_map.get(c, c) for c in df.columns}, inplace=True)\n",
    "\n",
    "print(\"üîé Columns after cleaning:\", df.columns.tolist())\n",
    "\n",
    "# --- Ensure required columns ---\n",
    "required_cols = [\"Date\", \"Close\", \"Volume\"]\n",
    "missing = [col for col in required_cols if col not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"‚ùå Missing required columns: {missing}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Preprocess Data\n",
    "# -------------------------------\n",
    "for col in [\"Close\", \"Open\", \"High\", \"Low\", \"Volume\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.replace(r\"[\\$,]\", \"\", regex=True)\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df.dropna(subset=[\"Date\", \"Close\"], inplace=True)\n",
    "df.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Feature Engineering\n",
    "# -------------------------------\n",
    "df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "df[\"MA5\"] = df[\"Close\"].rolling(5).mean()\n",
    "df[\"MA10\"] = df[\"Close\"].rolling(10).mean()\n",
    "df[\"Volatility\"] = df[\"Return\"].rolling(5).std()\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "features = [\"Return\", \"MA5\", \"MA10\", \"Volatility\"]\n",
    "X = df[features]\n",
    "y = df[\"Close\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# -------------------------------\n",
    "# Train/Test Split\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Train Model\n",
    "# -------------------------------\n",
    "model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate\n",
    "# -------------------------------\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"‚úÖ Training done: RMSE={rmse:.2f}, R¬≤={r2:.2f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Save Model + Artifacts\n",
    "# -------------------------------\n",
    "model.save_model(MODEL_PATH)\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "joblib.dump(features, FEATURES_PATH)\n",
    "\n",
    "# -------------------------------\n",
    "# Save Training Log (UTF-8 safe)\n",
    "# -------------------------------\n",
    "with open(LOG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Training Log: {datetime.now()}\\n\")\n",
    "    f.write(f\"Features used: {features}\\n\")\n",
    "    f.write(f\"Dataset size: {len(df)} rows\\n\")\n",
    "    f.write(f\"RMSE: {rmse:.2f}\\n\")\n",
    "    f.write(f\"R¬≤: {r2:.2f}\\n\")\n",
    "\n",
    "print(f\"üìå Model, scaler, features, and log saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
